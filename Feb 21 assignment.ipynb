{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa188064-04d5-4e5d-9f5d-baea306d2c5a",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.   \n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating a code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "\n",
    "Web scraping requires two parts, namely the crawler and the scraper. The crawler is an artificial intelligence algorithm that browses the web to search for the particular data required by following the links across the internet. The scraper, on the other hand, is a specific tool created to extract data from the website. The design of the scraper can vary greatly according to the complexity and scope of the project so that it can quickly and accurately extract the data. \n",
    "\n",
    "While we can do this manually, when projects require extracted data from hundreds or even thousands of web pages, automated web scraping tools can do the job more quickly and efficiently. \n",
    "\n",
    "E-Commerce   \n",
    "Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc. Product details like price, description, images, reviews, rating etc. can be easily extracted using a web scraping software.   \n",
    "\n",
    "Lead Generation for Marketing   \n",
    "A web scraping software can be used to generate leads for marketing. Email and Phone lists for cold outreach can be built by scraping the data from relevant websites. For example, business contact details like phone number and email address can be scraped from yellow pages websites or from Google Maps business listings.   \n",
    "\n",
    "Training and Testing Data for Machine Learning Projects  \n",
    "Web Scraping helps you to gather data for testing / training your Machine Learning models. Quality of your machine learning models depends on the quality of training data used and when the data is not readily available you can employ web scraping to collect it from various websites.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d476f-b574-46d3-9fd9-a1d2edde9278",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?  \n",
    "Human copy-and-paste. The simplest form of web scraping is manually copying and pasting data from a web page into a text file or spreadsheet.  \n",
    "Text pattern matching  \n",
    "HTML parsing   \n",
    "DOM parsing   \n",
    "Vertical aggregation    \n",
    "Semantic annotation recognizing   \n",
    "Computer vision web-page analysis   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147caa1-55a0-4ffa-9ab4-53335bd9ba74",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?  \n",
    "Beautiful Soup is a python package and as the name suggests, parses the unwanted data and helps to organize and format the messy web data by fixing bad HTML and present to us in an easily-traversible XML structures.\n",
    "\n",
    "In short, Beautiful Soup is a python package which allows us to pull data out of HTML and XML documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336472df-fa5c-49ce-b2f9-433c761460dc",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?  \n",
    "Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b504638-c0b1-42c6-af7a-d79b33876b14",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.  \n",
    "AWS services used in this project were code pipeline and Elastic Beanstalk\n",
    "\n",
    "AWS CodePipeline  \n",
    "AWS CodePipeline is a fully managed continuous delivery solution that assists you in automating your release pipelines for quick and dependable application and infrastructure changes. Based on the release model you set, CodePipeline automates the build, test, and deploy parts of your release process whenever there is a code change. This enables you to deploy features and updates in a timely and dependable manner. AWS CodePipeline may be easily integrated with third-party services such as GitHub or your own custom plugin. You only pay for what you use with AWS CodePipeline. There are no up-front costs or long-term obligation   \n",
    "\n",
    "AWS Elastic Beanstalk\n",
    "This is an easy-to-use service for deploying and scaling web applications and services developed with Java, .NET, PHP, Node.js, Python, Ruby, Go, and Docker on familiar servers such as Apache, Nginx, Passenger, and IIS.\n",
    "\n",
    "A developer can use AWS Elastic Beanstalk to launch an application without provisioning the underlying infrastructure and also retaining high availability. Simply upload your app and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, and auto-scaling to application health monitoring. At the same time, you maintain complete control over the AWS tools that power your application and can access them at any time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
